{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-08T13:58:49.840921Z",
     "start_time": "2024-08-08T13:58:49.824974Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from mtflearn.io import load_image\n",
    "from stemplot import imshow, colors_from_lbs\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load images, pts and lbs",
   "id": "b8355f375fdd735d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:19:19.887660Z",
     "start_time": "2024-08-08T14:19:19.873708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "def find_imgs(element):\n",
    "    dm4_files = glob.glob(f\"{element}/*.dm4\")\n",
    "    adf1_files = []\n",
    "    adf2_files = []\n",
    "    for file in dm4_files:\n",
    "        if \"ADF1\" in file and \"ADF2\" not in file:\n",
    "            adf1_files.append(file)\n",
    "        elif \"ADF2\" in file and \"ADF1\" not in file:\n",
    "            adf2_files.append(file)\n",
    "    return adf1_files, adf2_files\n",
    "\n",
    "def find_pts_and_lbs(element):\n",
    "    folder_path = f\"{element} pts and lbs\"\n",
    "    npy_files = glob.glob(f\"{folder_path}/*.npy\")\n",
    "    pts_files = []\n",
    "    lbs_files = []\n",
    "    for file in npy_files:\n",
    "        file_name = file.split(\"\\\\\")[-1]\n",
    "        if \"pts\" in file_name and \"lbs\" not in file_name:\n",
    "            pts_files.append(file)\n",
    "        elif \"lbs\" in file_name and \"pts\" not in file_name:\n",
    "            lbs_files.append(file)\n",
    "    return pts_files, lbs_files\n",
    "\n",
    "def find_matching_images(lbs_filenames, image_filenames):\n",
    "    matching_images = []\n",
    "    for lbs_file in lbs_filenames:\n",
    "        # 去除路径信息\n",
    "        file_name = lbs_file.split('\\\\')[-1]\n",
    "\n",
    "        # 检查文件名是否以数字或 \"E\" 开头\n",
    "        if re.match(r'^[0-9E]', file_name):\n",
    "            # 提取第一个下划线前的部分\n",
    "            base_name = file_name.split('_')[0]\n",
    "        else:\n",
    "            base_name = file_name\n",
    "\n",
    "        # 查找 \"Ti\", \"V\", \"Mn\", \"Co\" 中的一个，并提取其后的数字\n",
    "        match = re.search(r'(Ti|V|Mn|Co)(\\d+)', file_name)\n",
    "        if match:\n",
    "            element = match.group(1)\n",
    "            number = match.group(2)\n",
    "            pattern = f'{base_name}_{element}{number}'\n",
    "\n",
    "            # 在 image_filenames 中查找匹配项\n",
    "            for img_file in image_filenames:\n",
    "                if pattern in img_file:\n",
    "                    matching_images.append((lbs_file, img_file))\n",
    "                    break\n",
    "                    \n",
    "def find_matching_images(lbs_filenames,pts_filenames, adf1_filenames,adf2_filenames):\n",
    "    matching_images = []\n",
    "\n",
    "    for idx,lbs_file in enumerate(lbs_filenames):\n",
    "        files = []\n",
    "        files.append(lbs_file)\n",
    "        files.append(pts_filenames[idx])\n",
    "        file_name = lbs_file.split('\\\\')[-1]\n",
    "        if re.match(r'^[0-9E]', file_name):\n",
    "            base_name = file_name.split('_')[0]\n",
    "        else:\n",
    "            base_name = ''\n",
    "        match = re.search(r'(Ti|V|Mn|Co)(\\d+)', file_name)\n",
    "        if match:\n",
    "            number = match.group(2)\n",
    "            number = number+'.dm4'\n",
    "            for idx2,img_file in enumerate(adf1_filenames):\n",
    "                if base_name and (base_name in img_file and number in img_file):\n",
    "                    files.append(img_file)\n",
    "                    files.append(adf2_filenames[idx2])\n",
    "                    break\n",
    "                elif not base_name and number in img_file:\n",
    "                    files.append(img_file)\n",
    "                    files.append(adf2_filenames[idx2])\n",
    "                    break\n",
    "        matching_images.append(files)\n",
    "    return matching_images"
   ],
   "id": "74a7270984f2d8ab",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:21:22.097187Z",
     "start_time": "2024-08-08T14:21:22.078243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Ti_adf1,Ti_adf2 = find_imgs('Ti')\n",
    "Ti_pts,Ti_lbs = find_pts_and_lbs('Ti')\n",
    "Ti_pair_files = find_matching_images(Ti_lbs,Ti_pts,Ti_adf1,Ti_adf2)"
   ],
   "id": "2e7c619ecc51a16",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:22:17.715972Z",
     "start_time": "2024-08-08T14:22:17.703015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "V_adf1,V_adf2 = find_imgs('V')\n",
    "V_pts,V_lbs = find_pts_and_lbs('V')\n",
    "V_pair_files = find_matching_images(V_lbs,V_pts,V_adf1,V_adf2)"
   ],
   "id": "20db778e3b6869e5",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:22:40.634492Z",
     "start_time": "2024-08-08T14:22:40.625522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Mn_adf1,Mn_adf2 = find_imgs('Mn')\n",
    "Mn_pts,Mn_lbs = find_pts_and_lbs('Mn')\n",
    "Mn_pair_files = find_matching_images(Mn_lbs,Mn_pts,Mn_adf1,Mn_adf2)"
   ],
   "id": "90a177f1406052b8",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:23:07.993549Z",
     "start_time": "2024-08-08T14:23:07.975608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Co_adf1,Co_adf2 = find_imgs('Co')\n",
    "Co_pts,Co_lbs = find_pts_and_lbs('Co')\n",
    "Co_pair_files = find_matching_images(Co_lbs,Co_pts,Co_adf1,Co_adf2)"
   ],
   "id": "99f70dcb486bb04c",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a73304e346a38ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
